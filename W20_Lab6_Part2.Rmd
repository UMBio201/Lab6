---
title: 'Lab 6: Tidy data, Part 2'
author: "Kristi Gdanetz MacCready"
date: "02/12/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "~/Documents/UMBio201/Lab6/")
```

# Load packages
```{r Load packages, message=FALSE, warning=FALSE, include=FALSE, results='hide'}
library(tidyverse)
library(readxl)
library(broom)
library(cowplot)
set.seed(7)
```

# Import data
Load the curated data created during Part 1 if it is not already in your global environment
```{r}
avg_qc <- read_delim(file = "curated_data/avg_qc.txt", 
                      delim = "\t", na = "NA", col_names = TRUE)

bio2 <- read_delim(file = "curated_data/biographical_data.txt", 
                   delim = "\t", na = "NA", col_names = TRUE)
```


# Reshaping data + Long format

Remember, a tidy data set can be identified if the following conditions are met: 

* Each variable has its own column
* Each observation has its own row
* Each value must have its own cell

To match all these conditions, the data frame usually must be in long format. You have been working with long format (or pseudo-long) so far this semester. Many of the data frames we have used have a value (column) for study week since this is a "measured" characteristic of each sample, thus there are multiple rows for each participant; this is long-formatted data. In contrast, if the measurements for week 1 and week 3 were in their own columns and there was only one row per particpant, this would be wide-formatted data. When working with collaborators, you will often receive wide-formatted data; this is okay since it easy to read and intuitive to type into spreadsheet software (like Excel). However when we want to plot and analyze these data, you will need to convert it to long-format. We can do these transformations with two complimentary tidyr functions, spread() and gather().

### Spread

Sometimes we are interested in calculating the difference in SCFA concentrations (or other measurements) between weeks of the study, how is this accomplished in long format? It isn’t. The data frame should be converted to a wide format, then calculations can be performed across columns with mutate(). Each row of the wide table will contain measurements associated with both weeks. This means the values of butyrate concentrations during weeks 1 and 3 would become the names of column variables. 

spread() takes long data and makes it wide, spread() takes three principal arguments: 

* the data
* the key column variable whose values will become new column names.
* the value column variable whose values will fill the new column variables.

Optional arguments include ‘fill’ which, if included, fills in missing values with the value provided (almost always NA is appropriate). Use spread() to widen the data frame by study week. Inspect the result, can you determine what happened here? 
```{r}
avg_qc %>%
  spread(key = study_week, value = butyrate_mean)
```

View/click-through the output, notice there are a lot of NAs and extra weeks (weeks 4 & 5). To simplify the output, filter by SCFA of interest before spreading. We use filter() and select() to subset the data frame to observations and variables of interest. 
```{r}
avg_qc %>%
  # keep only columns of interest
  select(participant_id, semester, supplement_consumed, 
         frequency, study_week, butyrate_mean) %>% 
  # keep only weeks of interest
  filter(study_week == "week1" | study_week == "week3") %>% 
  # widen data frame
  spread(study_week, butyrate_mean) 
```

Notice there are some rows containing NAs, we cannot calculate a difference if the data for one of the weeks are missing, remove those using drop_na() on these columns. This yields a data frame where the observations for each week are spread across multiple columns. Now use mutate to calculate the difference between weeks, and save as a new data frame.
```{r}
butyrate_delta <- avg_qc %>%
  # keep only columns of interest
  select(participant_id, semester, supplement_consumed, 
         frequency, study_week, butyrate_mean) %>% 
  # keep only weeks of interest
  filter(study_week == "week1" | study_week == "week3") %>% 
  # widen data frame
  spread(study_week, butyrate_mean)  %>%
  # drop NAs from select columns
  drop_na(week1, week3) %>% 
  # calculate difference
  mutate(delta_butyrate = week3 - week1) %>%  
  # drop extra columns
  select(-week3, -week1) 

head(butyrate_delta)
```

### Gather

Often collaborators collect and enter data in a wide formatted spreadsheet, which is understandable since it is a little easier for humans to read, however we need the data in long format for analysis. Additionally, you may need to return a wide data frame to long format after you've conducted some manipulation. We can complete this with gather(), the opposite of the spread() function. 

gather() takes four principal arguments:

* the data
* the key column variable we wish to create from column names.
* the values column variable we wish to create and fill with values associated with the key.
* the names of the columns we use to fill the key variable (or to drop).

In this situation we are gathering the multiple columns and turning them into a pair of new variables. One variable represents the column names as values, and the other variable contains the values/measurements previously found under each column name.

Remember when we conducted paired t-tests? The t.test() function will throw an error if one half of a pair is missing. One way to identify missing pairs is to make a wide data frame, then drop any NAs (just like we did above). The additional step is to return this wide data frame to long format. 
```{r}
butyrate_paired <- avg_qc %>%
  select(participant_id, semester, supplement_consumed, 
         frequency, study_week, butyrate_mean) %>% 
  filter(study_week == "week1" | study_week == "week3") %>% 
  spread(study_week, butyrate_mean)  %>%
  drop_na(week1, week3) %>% 
  # convert to long format
  gather(key = "study_week", value = "butyrate_mean", week1, week3) %>%
  # sort by ID column
  arrange(participant_id)

butyrate_paired
```

This process can be repeated for each of the measured SCFAs. The order of the functions are the same, just the column names and resulting data frames have been modified: 
```{r}
# acetate
acetate_paired <- avg_qc %>%
  select(participant_id, semester, supplement_consumed, 
         study_week, frequency, acetate_mean) %>% 
  filter(study_week == "week1" | study_week == "week3") %>% 
  spread(key = "study_week", value = "acetate_mean") %>% 
  drop_na(week1, week3) %>% 
  gather(key = "study_week", value = "acetate_mean", week1, week3) %>%
  arrange(participant_id)

# propionate
propionate_paired <- avg_qc %>%
  select(participant_id, semester, study_week, 
         supplement_consumed, frequency,  propionate_mean) %>% 
  filter(study_week == "week1" | study_week == "week3") %>% 
  spread(key = "study_week", value = "propionate_mean") %>% 
  drop_na(week1, week3) %>% 
  gather(key = "study_week", value = "propionate_mean", week1, week3) %>%
  arrange(participant_id)
```


# Join

Many data analysis tasks can be approached using the split-apply-combine paradigm: 

* split the data into groups
* apply some analysis to each group
* combine the results

We just completed the first two steps in the section above, where we created a new dataframe and removed NAs for each of the SCFAs. Joins are used to combine/merge two data frames. There are several flavors of join functions, type `?join` into the console to view them all, and read about their differing behaviors. We can check the results of our joins by identifying the number of rows and participants in each data frame before and after the join. 
```{r}
# determine size of acetate group before join
dim(acetate_paired) #1002, 6
n_distinct(acetate_paired$participant_id) #501

# determine size of butyrate group before join
dim(butyrate_paired) #990, 6
n_distinct(butyrate_paired$participant_id) #495

# determine size of propionate group before join
dim(propionate_paired) #928, 6
n_distinct(propionate_paired$participant_id) #464
```

Compare the numbers above. We have differing numbers of participants in each group because our QC protocol causes some SCFA measurements to be dropped, but not others. 

### Inner 
```{r}
# inner_join example
join1 <- inner_join(acetate_paired, butyrate_paired)
dim(join1) #978, 7
n_distinct(join1$participant_id) #489
```
The result of the inner join has fewer participants (489) than either the acetate (501) or butyrate (495) data frames alone. This means there are only 489 IDs shared between these two data frames. If a sample is missing from one of the data frames, it is excluded from the resulting data frame.

### Left or right
There may be some scenarios in which you want to retain the data without a match, this can be accomplished with a left/right_join() or full_join(), which return combinations of matches and non-matches.
```{r}
# left_join example
join2 <- left_join(acetate_paired, butyrate_paired)
dim(join2) #1002, 7
n_distinct(join2$participant_id) #501
```
The result of the left join has the same number of participants as the acetate data frame (501). This is because the acetate_paired data frame was entered as the first argument (left) to this function. All data in the left data frame is kept, and anything from the right data frame (second argument) is added. If there are values in the right data frame missing from the left, they are not retained. 

If you kept all arguments the same but used right_join(), the number of participants would be the same as that in the butyrate data frame.

### Full 
```{r}
# full_join example
join3 <- full_join(acetate_paired, butyrate_paired)
dim(join3) #1014, 7
n_distinct(join3$participant_id) #507
```
The full join has more participants than either of the data frames alone (507 vs. 501 or 496). It may be helpful to think of a full join as simultaneous left and right joins. All matches are retained, and any non-matches are populated with NA values. There is not data loss in a full join.

### Final join 

Join functions take two arguments (two dataframes). If you want to join additional data frames just use the handy pipes. Any join functions after the first only need one data frame specified. Use the three data frames you created in the section above (acetate_paired, butyrate_paired, propionate_paired) to practice joins. 
```{r}
# use only inner joins
join4 <- inner_join(acetate_paired, butyrate_paired) %>%
  inner_join(propionate_paired)

# check results
dim(join4) #902, 8
n_distinct(join4$participant_id) #451
```
Just like when you conducted an inner join on two data frames, an additional paired join with a third futher reduces the final number of participants to 451.

```{r}
# use only full joins
join5 <- full_join(acetate_paired, butyrate_paired) %>%
  full_join(propionate_paired)

# check results 
dim(join5) #1016, 8
n_distinct(join5$participant_id) #508

dim(avg_qc) #1296, 11
n_distinct(avg_qc$participant_id) #577
```
Piped full joins results in the largest number of participants retained (508) of any combination. So if our goal is to retain as many participants as possibe with paired samples (values in both week 1 and 3) using full joins in the best option. 

# Save data 
```{r}
write_delim(join5, delim = "\t", na = "NA", col_names = TRUE,
            path = "curated_data/joined_results.txt")
```


-----
end